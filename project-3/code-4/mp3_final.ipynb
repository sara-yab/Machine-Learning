{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d6ea5cb87c584affb765a6b6f58ef8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_509262379c76445cad55c3a6438ad0d6",
              "IPY_MODEL_d8f0ec85e3224e03aa0c71da9e5f2c24",
              "IPY_MODEL_c3540e20c4834387a6e5b66fe8c21996"
            ],
            "layout": "IPY_MODEL_d75bdf0e17f141749a0212670aea3e08"
          }
        },
        "509262379c76445cad55c3a6438ad0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885795bfa0294779aa2aebd3df1f4399",
            "placeholder": "​",
            "style": "IPY_MODEL_fad3062dc7d04262b6bf0992d92bb40f",
            "value": "Validation Accuracy : 93.542: 100%"
          }
        },
        "d8f0ec85e3224e03aa0c71da9e5f2c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2357b79651b446619cda565012741f90",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2c833c8673471485191b87565b7c26",
            "value": 5
          }
        },
        "c3540e20c4834387a6e5b66fe8c21996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7e52f99d2e4b6f89a88a175fc8cbae",
            "placeholder": "​",
            "style": "IPY_MODEL_7f898c1631304a03a9ac94f5428087e6",
            "value": " 5/5 [01:52&lt;00:00, 21.30s/it]"
          }
        },
        "d75bdf0e17f141749a0212670aea3e08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885795bfa0294779aa2aebd3df1f4399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad3062dc7d04262b6bf0992d92bb40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2357b79651b446619cda565012741f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2c833c8673471485191b87565b7c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c7e52f99d2e4b6f89a88a175fc8cbae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f898c1631304a03a9ac94f5428087e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wrkCEo0V1rRh"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision.datasets import KMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "from skimage.util import img_as_ubyte\n",
        "from torchvision.models import VGG, vgg16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if using GPU \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "  print(f\"Nvidia Cuda/GPU is available!\")\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW2HsdydGAD_",
        "outputId": "62813d0d-b67a-4235-bae2-93092ec627ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nvidia Cuda/GPU is available!\n",
            "Sun Apr 16 22:57:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    11W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phrtAJQn14tg",
        "outputId": "d22af4cf-ca64-4c1d-f636-f0482ebd4595"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Folder of the  drive is accessed\n",
        "%cd '/content/gdrive/MyDrive/ecse551-mp3'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsLAgEtt03-K",
        "outputId": "2bc5b2fe-9f0f-4120-f78e-efb33f923f3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/ecse551-mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read a pickle file and disply its samples\n",
        "# Note that image data are stored as unit8 so each element is an integer value between 0 and 255\n",
        "train_data  = pickle.load( open( './Train.pkl', 'rb' ), encoding='bytes').reshape(-1,28,28) \n",
        "train_targets   = np.genfromtxt('./Train_labels.csv', delimiter=',', skip_header=1)[:,1:]\n",
        "test_data  = pickle.load( open( './Test.pkl', 'rb' ), encoding='bytes')\n",
        "plt.imshow(train_data[0,:,:].squeeze(),cmap='gray')\n",
        "\n",
        "print('Training data shape:', train_data.shape)\n",
        "print('Training targets shape:', train_targets.shape)\n",
        "print('Test data shape:', test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "gS-3zAIg2Brp",
        "outputId": "845d9ef3-9132-4056-8b6e-31a85bb1b61d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 28, 28)\n",
            "Training targets shape: (60000, 1)\n",
            "Test data shape: (10000, 1, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset class\n",
        "#Dataloader class"
      ],
      "metadata": {
        "id": "baNKYCNi2tV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute training data's mean and standard deviation\n",
        "#Divide by 255 to scale grayscale values (0-255) to 0-1 range for neural network input\n",
        "\n",
        "train_data = np.random.random((100, 100)) # Example data\n",
        "\n",
        "mean_val = np.mean(train_data) / 255 # Compute the mean of the pixel values\n",
        "std_val = np.std(train_data) / 255 # Compute the standard deviation of the pixel values\n",
        "\n",
        "print(f\"Mean: {mean_val}, Standard Deviation: {std_val}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrRmsKLG_a5U",
        "outputId": "25875566-1aa9-4744-8b35-ed5bf61ef3a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 0.001961744867166121, Standard Deviation: 0.0011254305365648407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**img_transform preprocessing**"
      ],
      "metadata": {
        "id": "U5NjgpixEdFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms are common image transformations. They can be chained together using Compose.\n",
        "''' \n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomAffine(degrees=5), ### hyperparameter \"degrees\" ###\n",
        "])\n",
        "'''\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomAffine(degrees=5), ### hyperparameter \"degrees\" ###\n",
        "    transforms.Normalize([mean_val], [std_val]) ### hyperparameters \"mean\" and \"std\" ###\n",
        "])\n",
        "'''\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomAffine(degrees=5), ### hyperparameter \"degrees\" ###\n",
        "    transforms.Normalize(0.5, 0.5) ### hyperparameters \"mean\" and \"std\" ###\n",
        "])\n",
        "'''"
      ],
      "metadata": {
        "id": "B5agcKMN2sgf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "cd780704-4c52-4b09-8e66-9d4d22048ac9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Doesnt work\\nimg_transform = transforms.Compose([\\n    transforms.ToTensor(),\\n    transforms.RandomAffine(degrees=5), ### hyperparameter \"degrees\" ###\\n    transforms.Normalize(0.5, 0.5) ### hyperparameters \"mean\" and \"std\" ###\\n])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetTrain(Dataset):\n",
        "  def __init__(self, image_file, label_file, data_transform=None, idx = None): \n",
        "    self.image_data = pickle.load( open( image_file, 'rb' ), encoding='bytes') # load the image data                     \n",
        "    self.label_data = np.genfromtxt(label_file, delimiter=',', skip_header=1)[:,1:] # skip the first row\n",
        "    self.data_transform = data_transform\n",
        "    \n",
        "    if idx is not None:\n",
        "      self.label_data = self.label_data[idx] # select the idx-th row\n",
        "      self.image_data = self.image_data[idx] # select the idx-th row\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.label_data) # return the number of samples\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.image_data[idx], int(self.label_data[idx]) # get the idx-th sample\n",
        "\n",
        "    if self.data_transform is not None: # if there is a transform given, apply this transform to the image\n",
        "      image = image.reshape(28,28) # reshape the image to 28x28\n",
        "      image = Image.fromarray(image.astype('float'), mode='1') # convert the image to PIL image, mode='1' means the image is binary                  \n",
        "      image = self.data_transform(image) # apply the transform to the image\n",
        "\n",
        "    return image, label\n"
      ],
      "metadata": {
        "id": "w3Olr0ilea0G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetTest(Dataset):\n",
        "    \n",
        "    def __init__(self, img_path, transform=None, indices=None):\n",
        "        self.images = pickle.load(open(img_path, 'rb'))\n",
        "\n",
        "        if indices is not None:\n",
        "            self.images = self.images[indices]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.images[index]\n",
        "        image = Image.fromarray(image.astype('uint8'), mode='L')\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "4298lRrtFsKw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ---- Load data for entire training set ---- ##\n",
        "# Read image data and their label into a Dataset object #\n",
        "\n",
        "## Note:- Selecting approximately 1000 test data from the set of 60000 as well. \n",
        "\n",
        "training_dataset = CustomDatasetTrain('./Train.pkl', './Train_labels.csv', idx=None)\n",
        "\n",
        "# Load data using DataLoader\n",
        "batch_size = 32                                                             # Set batch size based on the size of the training or test data\n",
        "training_data = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)  "
      ],
      "metadata": {
        "id": "8G_eQ9nJ1SFb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = enumerate(training_data)\n",
        "idx, (inputs, targets) = next(data)\n",
        "print(inputs.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(inputs[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "fV-3KUJ8i1ej",
        "outputId": "842f58e0-66b9-4826-d98a-72e4ca8b846c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read a batch of data and their labels and display them\n",
        "data_batch, target_labels = next(iter(training_data))\n",
        "image = np.squeeze(data_batch)\n",
        "plt.imshow(image[1].reshape(28, 28).cpu().numpy(), cmap='binary', vmin=0, vmax=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "0yShITes8Qcj",
        "outputId": "9ce7c811-62b3-4feb-d956-f83b11b7013e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31b9461460>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_file = 'Test.pkl'\n",
        "test_batch_size = 32\n",
        "\n",
        "# Load test data using pickle\n",
        "with open(test_file, 'rb') as file:\n",
        "    test_data = DataLoader(pickle.load(file, encoding='bytes'), batch_size=test_batch_size)\n"
      ],
      "metadata": {
        "id": "OWZNQ00yq3bT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape when dataloader is used.\n",
        "print(data_batch.shape)\n",
        "print(target_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHLpEPH28hXZ",
        "outputId": "4fac52dd-5b7e-4e8e-cea9-344836092c6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet - CNN"
      ],
      "metadata": {
        "id": "XP4TSKDH7vqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
        "\n",
        "# ---- Modified ResNet 18 ----- #\n",
        "class ModifiedResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(ModifiedResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "\n",
        "model_resnet = ModifiedResNet()\n",
        "\n",
        "adam_optimizer = optim.Adam(model_resnet.parameters(), lr=0.001)\n",
        "loss_criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "5pOkUL7W4qM0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Testing on ResNet"
      ],
      "metadata": {
        "id": "tGCIrIOw7xmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dropout probability\n",
        "dropout_prob = 0.2\n",
        "\n",
        "# Clone ResNet model\n",
        "num_ft = model_resnet.fc.in_features\n",
        "\n",
        "# Replace fully connected layer with a new one with dropout\n",
        "new_fc = nn.Sequential(nn.Dropout(p=dropout_prob), nn.Linear(num_ft, 10))\n",
        "model_resnet.fc = new_fc\n",
        "\n",
        "# Move the model to GPU\n",
        "model_resnet.to('cuda')\n"
      ],
      "metadata": {
        "id": "RxEWCxgT75rW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f01d567-a716-4b08-f15f-071ae290f76f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModifiedResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet Model - Training & Validation"
      ],
      "metadata": {
        "id": "6j8K0Fn2-qFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load training data and labels\n",
        "train_data_source = CustomDatasetTrain('./Train.pkl', './Train_labels.csv', idx=None) # Load training data and labels\n",
        "\n",
        "# Define sizes of training and validation sets\n",
        "training_portion = int(0.8 * len(train_data_source)) # 80% of the data is used for training\n",
        "validation_portion = len(train_data_source) - training_portion # 20% of the data is used for validation\n",
        "\n",
        "# Split data into training and validation sets, using random_split\n",
        "train_subset, validation_subset = torch.utils.data.random_split(train_data_source, [training_portion, validation_portion])\n",
        "\n",
        "# Load data using DataLoader\n",
        "data_batch_size = 100\n",
        "train_loader = DataLoader(train_subset, batch_size=data_batch_size, shuffle=True) \n",
        "validation_loader = DataLoader(validation_subset, batch_size=data_batch_size, shuffle=True) \n",
        "\n",
        "## ----- Training Function for the ResNet ----- ##\n",
        "\n",
        "def resnet_training(epoch, train_loader):\n",
        "  model_resnet.train() # Set the model to training mode\n",
        "  correct_predictions = 0 # Initialize the number of correct predictions\n",
        "  total_predictions = 0 # Initialize the number of total predictions\n",
        "  for idx, (data, label) in enumerate(train_loader): # Iterate over the training data\n",
        "    data, label = data.cuda(), label.cuda() # Move the data and labels to the GPU\n",
        "    adam_optimizer.zero_grad() # Clear the gradients\n",
        "    model_output = model_resnet(data).cuda() # Forward pass\n",
        "    _, prediction = torch.max(model_output.data, 1) # Get the predictions\n",
        "\n",
        "    correct_predictions += (prediction == label).sum().item() # Update the number of correct predictions\n",
        "    loss = loss_criterion(model_output, label) # Calculate the loss           \n",
        "    total_predictions += label.size(0) # Update the number of total predictions\n",
        "    accuracy_pct = (correct_predictions / total_predictions) * 100.0 # Calculate the accuracy\n",
        "    progress_visual.set_description(f\"Loss : {loss.item():.3f}, Training Accuracy : {accuracy_pct:.3f}\") # Update the progress bar\n",
        "\n",
        "    loss.backward() # Backward pass\n",
        "    adam_optimizer.step() # Update the weights\n",
        "\n",
        "  print(f'Epoch : {epoch}; Training Accuracy: {accuracy_pct:.3f}') # Print the training accuracy\n",
        "\n",
        "## ----- Validation Function for the ResNet ----- ##\n",
        "\n",
        "def resnet_validatation(epoch, validation_loader): # Validation function\n",
        "  correct_predictions = 0 # Initialize the number of correct predictions\n",
        "  total_predictions = 0 # Initialize the number of total predictions\n",
        "  highest_accuracy = 0 # Initialize the highest accuracy\n",
        "  for idx, (data, label) in enumerate(validation_loader): # Iterate over the validation data\n",
        "    data, label = data.cuda(), label.cuda() # Move the data and labels to the GPU\n",
        "    model_output = model_resnet(data).cuda() # Forward pass\n",
        "    _, prediction = torch.max(model_output.data, 1) # Get the predictions\n",
        "    correct_predictions += (prediction == label).sum().item() # Update the number of correct predictions\n",
        "    total_predictions += label.size(0) # Update the number of total predictions\n",
        "    accuracy_pct = (correct_predictions / total_predictions) * 100.0 # Calculate the accuracy\n",
        "    progress_visual.set_description(f\"Validation Accuracy : {accuracy_pct:.3f}\") # Update the progress bar\n",
        "\n",
        "    if accuracy_pct > highest_accuracy: \n",
        "      highest_accuracy = accuracy_pct\n",
        "\n",
        "  print(f'Epoch : {epoch}; Validation Accuracy: {accuracy_pct:.3f}')\n",
        "  return highest_accuracy\n",
        "\n",
        "\n",
        "## ----- Running the epochs of ResNet ----- ##\n",
        "\n",
        "iteration_count = 5 # Set the number of iterations to run\n",
        "best_epoch = 0\n",
        "progress_visual = tqdm_notebook(iterable=range(iteration_count), position=0, leave=True)\n",
        "highest_accuracy = 0\n",
        "begin_time = time.time()\n",
        "\n",
        "for idx in progress_visual: # Iterate over the number of iterations\n",
        "  resnet_training(idx + 1, train_loader) # Run the training function\n",
        "  curr_val_acc = resnet_validatation(idx + 1, validation_loader) # Get the current validation accuracy\n",
        "  if curr_val_acc > highest_accuracy: # Check if the current validation accuracy is higher than the highest accuracy\n",
        "    highest_accuracy = curr_val_acc # Store the highest accuracy\n",
        "    best_epoch = idx # Store the epoch with the highest accuracy\n",
        "    torch.save(model_resnet.state_dict(), '/model.pth') # Save the model\n",
        "    torch.save(adam_optimizer.state_dict(), '/optimizer.pth') # Save the optimizer\n",
        "\n",
        "finish_time = time.time() # Get the time when the training is finished\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "d6ea5cb87c584affb765a6b6f58ef8e0",
            "509262379c76445cad55c3a6438ad0d6",
            "d8f0ec85e3224e03aa0c71da9e5f2c24",
            "c3540e20c4834387a6e5b66fe8c21996",
            "d75bdf0e17f141749a0212670aea3e08",
            "885795bfa0294779aa2aebd3df1f4399",
            "fad3062dc7d04262b6bf0992d92bb40f",
            "2357b79651b446619cda565012741f90",
            "8f2c833c8673471485191b87565b7c26",
            "1c7e52f99d2e4b6f89a88a175fc8cbae",
            "7f898c1631304a03a9ac94f5428087e6"
          ]
        },
        "id": "UFdcBMRl53tQ",
        "outputId": "fcd48e90-504d-4424-b944-0a9e67065536"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6ea5cb87c584affb765a6b6f58ef8e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1; Training Accuracy: 72.785\n",
            "Epoch : 1; Validation Accuracy: 86.208\n",
            "Epoch : 2; Training Accuracy: 89.385\n",
            "Epoch : 2; Validation Accuracy: 90.250\n",
            "Epoch : 3; Training Accuracy: 92.721\n",
            "Epoch : 3; Validation Accuracy: 91.758\n",
            "Epoch : 4; Training Accuracy: 94.833\n",
            "Epoch : 4; Validation Accuracy: 92.475\n",
            "Epoch : 5; Training Accuracy: 95.975\n",
            "Epoch : 5; Validation Accuracy: 93.542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test and Save data"
      ],
      "metadata": {
        "id": "Mi7_xnYmFsLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader_final = test_data # This is the test data loader\n",
        "predictions = []\n",
        "\n",
        "def make_prediction(test_data=test_data):\n",
        "    # Set the model to evaluation mode\n",
        "    model_resnet.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for single_data in test_data: \n",
        "            # Transfer data to the device (CPU or GPU)\n",
        "            single_data = single_data.to(device)\n",
        "\n",
        "            model_output = model_resnet(single_data)\n",
        "            prediction = model_output.data.max(1, keepdim=True)[1]\n",
        "            predictions.append(prediction.tolist())\n",
        "\n",
        "    flattened_predictions = [item for sublist in predictions for item in sublist] # Flatten the list, since the predictions are in a list of lists\n",
        "    final_predictions = [item for sublist in flattened_predictions for item in sublist] # Flatten the list, since the predictions are in a list of lists\n",
        "    return final_predictions\n",
        "\n",
        "def save_csv(predicted_data, output_file_name): # Save the predictions to a csv file\n",
        "    formatted_data = {'id': np.arange(10000), 'class': predicted_data} # Create a dictionary with the data\n",
        "    df = pd.DataFrame(formatted_data, columns=['id', 'class']) # Create a pandas dataframe with the data\n",
        "    df.to_csv(output_file_name, index=False, header=True) # Save the dataframe to a csv file\n",
        "    print(\"Data saved successfully! Check file name submit.csv\") # Print a message to the user\n"
      ],
      "metadata": {
        "id": "al74ws_3_BJB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Record the start time of the program, make predictions, and record the end time \n",
        "start_time = time.time()\n",
        "predictions_made = make_prediction(test_data=test_data) # Make predictions on the test set\n",
        "\n",
        "print(f\"Execution Time: {time.time() - start_time:.2f} seconds\") # Print the execution time\n",
        "\n",
        "save_csv(predictions_made, \"submit.csv\") # Save the predictions to a csv file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pknBJ4uyF3yA",
        "outputId": "58235c02-8164-40ad-c6bd-63ada2da15f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution Time: 1.30 seconds\n",
            "Data saved successfully! Check file name submit.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Other training and validation codes, including ResNet 18 loss graph, ResNet 34, leakyReLU (with SGD optimizer) layers and VGG 16**"
      ],
      "metadata": {
        "id": "II51ug1BtnDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet 18 loss graph:**"
      ],
      "metadata": {
        "id": "PRMvjCEAQA4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "#showing loss in graph fo report \n",
        "\n",
        "\n",
        "sequence = list(range(0, 10000, 1)) # Create a sequence of numbers from 0 to 10000\n",
        "batch_size = 32 # Set the batch size\n",
        "grouped_sequence = [sequence[i:i + batch_size] for i in range(0, len(sequence), batch_size)] # Group the sequence into batches of size 32\n",
        "\n",
        "test_idx = [i * len(training_data.dataset) for i in range(3)] # Create a list of indices to sample from the test set\n",
        "peak_accuracy = 0 # Initialize peak accuracy to zero\n",
        "average_accuracy = 0 # Initialize average accuracy to zero\n",
        "\n",
        "num_iterations = 5 # Setting the number of epochs to run\n",
        "progress_indicator = tqdm_notebook(iterable=range(num_iterations), position=0, leave=True) # Create a progress indicator\n",
        "\n",
        "init_time = time.time() # Record the time at the start of training\n",
        "\n",
        "loss_history = [] # Create an empty list to store training losses after each epoch\n",
        "\n",
        "for current_epoch in progress_indicator: # Loop over the number of epochs\n",
        "  model_resnet.train() # Set the model to training mode\n",
        "  correct_predictions = 0 # Initialize correct predictions to zero\n",
        "  total_predictions = 0 # Initialize total predictions to zero\n",
        "  epoch_losses = 0 # Initialize epoch loss to zero \n",
        "  for batch_idx, (data_points, labels) in enumerate(training_data): # Loop over the training data\n",
        "    data_points, labels = data_points.cuda(), labels.cuda() # Move data to GPU\n",
        "    adam_optimizer.zero_grad() # Clear the gradients\n",
        "    model_output = model_resnet(data_points).cuda() # Forward pass\n",
        "    _, predicted_labels = torch.max(model_output, 1) # Get the predicted labels\n",
        "    correct_predictions += (predicted_labels == labels).sum().item() # Update the number of correct predictions\n",
        "    batch_loss = loss_criterion(model_output, labels) # Compute the loss\n",
        "    total_predictions += labels.size(0) # Update the total number of predictions\n",
        "    accuracy_pct = (correct_predictions / total_predictions) * 100.0 # Compute the accuracy\n",
        "    progress_indicator.set_description(f\"Loss : {batch_loss.item():.3f}, Main Data Accuracy : {accuracy_pct:.3f}\") # Update the progress indicator\n",
        "    epoch_losses += batch_loss.item() # Add batch loss to epoch loss \n",
        "    batch_loss.backward() # Backpropagate the loss\n",
        "    adam_optimizer.step() # Update the model parameters\n",
        "\n",
        "  loss_history.append(epoch_losses / len(training_data))  # Save average training loss after each epoch\n",
        "\n",
        "  print(f'Epoch : {current_epoch + 1} ; Training Loss on main data: {epoch_losses / len(training_data):.3f}') # Print the training loss after each epoch\n",
        "\n",
        "\n",
        "plt.plot(range(1, num_iterations + 1), loss_history) # Plot the training loss vs epoch\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss vs Epoch')\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "PGersSmeP7Sk",
        "outputId": "7897c5b9-6501-4e47-bb88-9f8e35c42316"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#showing loss in graph fo report \\n\\n\\nsequence = list(range(0, 10000, 1)) # Create a sequence of numbers from 0 to 10000\\nbatch_size = 32 # Set the batch size\\ngrouped_sequence = [sequence[i:i + batch_size] for i in range(0, len(sequence), batch_size)] # Group the sequence into batches of size 32\\n\\ntest_idx = [i * len(training_data.dataset) for i in range(3)] # Create a list of indices to sample from the test set\\npeak_accuracy = 0 # Initialize peak accuracy to zero\\naverage_accuracy = 0 # Initialize average accuracy to zero\\n\\nnum_iterations = 5 # Setting the number of epochs to run\\nprogress_indicator = tqdm_notebook(iterable=range(num_iterations), position=0, leave=True) # Create a progress indicator\\n\\ninit_time = time.time() # Record the time at the start of training\\n\\nloss_history = [] # Create an empty list to store training losses after each epoch\\n\\nfor current_epoch in progress_indicator: # Loop over the number of epochs\\n  model_resnet.train() # Set the model to training mode\\n  correct_predictions = 0 # Initialize correct predictions to zero\\n  total_predictions = 0 # Initialize total predictions to zero\\n  epoch_losses = 0 # Initialize epoch loss to zero \\n  for batch_idx, (data_points, labels) in enumerate(training_data): # Loop over the training data\\n    data_points, labels = data_points.cuda(), labels.cuda() # Move data to GPU\\n    adam_optimizer.zero_grad() # Clear the gradients\\n    model_output = model_resnet(data_points).cuda() # Forward pass\\n    _, predicted_labels = torch.max(model_output, 1) # Get the predicted labels\\n    correct_predictions += (predicted_labels == labels).sum().item() # Update the number of correct predictions\\n    batch_loss = loss_criterion(model_output, labels) # Compute the loss\\n    total_predictions += labels.size(0) # Update the total number of predictions\\n    accuracy_pct = (correct_predictions / total_predictions) * 100.0 # Compute the accuracy\\n    progress_indicator.set_description(f\"Loss : {batch_loss.item():.3f}, Main Data Accuracy : {accuracy_pct:.3f}\") # Update the progress indicator\\n    epoch_losses += batch_loss.item() # Add batch loss to epoch loss \\n    batch_loss.backward() # Backpropagate the loss\\n    adam_optimizer.step() # Update the model parameters\\n\\n  loss_history.append(epoch_losses / len(training_data))  # Save average training loss after each epoch\\n\\n  print(f\\'Epoch : {current_epoch + 1} ; Training Loss on main data: {epoch_losses / len(training_data):.3f}\\') # Print the training loss after each epoch\\n\\n\\nplt.plot(range(1, num_iterations + 1), loss_history) # Plot the training loss vs epoch\\nplt.xlabel(\\'Epoch\\')\\nplt.ylabel(\\'Training Loss\\')\\nplt.title(\\'Training Loss vs Epoch\\')\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet 34 CNN model**"
      ],
      "metadata": {
        "id": "JQvdB7BAQLnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class CustomResNet34(ResNet):\n",
        "  def __init__(self):\n",
        "    super(CustomResNet, self).init(BasicBlock, [3, 4, 6, 3], num_classes=10)\n",
        "    self.initial_conv = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tFCwWfbdQNsP",
        "outputId": "0bd15160-fb28-49d8-d459-40c5b47de274"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass CustomResNet34(ResNet):\\n  def __init__(self):\\n    super(CustomResNet, self).init(BasicBlock, [3, 4, 6, 3], num_classes=10)\\n    self.initial_conv = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LeakyReLU & SGD optimizer**"
      ],
      "metadata": {
        "id": "R7I6mOIidj5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' ignore to try leakyRelu\n",
        "# ---- Modified ResNet 18 ----- #\n",
        "class ModifiedResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(ModifiedResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "\n",
        "model_resnet = ModifiedResNet()\n",
        "\n",
        "adam_optimizer = optim.Adam(model_resnet.parameters(), lr=0.001)\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "'''\n",
        "''' Ignored for leakyRelu\n",
        "# Define dropout probability\n",
        "dropout_prob = 0.2\n",
        "\n",
        "# Clone ResNet model\n",
        "num_ft = model_resnet.fc.in_features\n",
        "\n",
        "# Replace fully connected layer with a new one with dropout\n",
        "new_fc = nn.Sequential(nn.Dropout(p=dropout_prob), nn.Linear(num_ft, 10))\n",
        "model_resnet.fc = new_fc\n",
        "\n",
        "# Move the model to GPU\n",
        "model_resnet.to('cuda')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Vhg9zpqQdmNN",
        "outputId": "977ad4ed-d6f9-4aba-aa8c-a0eb04e11638"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Ignored for leakyRelu\\n# Define dropout probability\\ndropout_prob = 0.2\\n\\n# Clone ResNet model\\nnum_ft = model_resnet.fc.in_features\\n\\n# Replace fully connected layer with a new one with dropout\\nnew_fc = nn.Sequential(nn.Dropout(p=dropout_prob), nn.Linear(num_ft, 10))\\nmodel_resnet.fc = new_fc\\n\\n# Move the model to GPU\\nmodel_resnet.to('cuda')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Leaky ReLU\n",
        "from torch.nn import LeakyReLU\n",
        "class LeakyBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(LeakyBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.relu = LeakyReLU(negative_slope=0.01, inplace=True)\n",
        "\n",
        "# ---- LeakyRELU ----- #\n",
        "class MFResNetLeaky(ResNet):\n",
        "    def __init__(self):\n",
        "        super(MFResNetLeaky, self).__init__(LeakyBasicBlock, [2, 2, 2, 2], num_classes=10) # Based on ResNet18\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\n",
        "\n",
        "model_resnet = MFResNetLeaky()\n",
        "\n",
        "#Create separate optimizers and criteria for Resnet\n",
        "adam_optimizer = optim.Adam(model_resnet.parameters(), lr=0.001) #adam optimizer\n",
        "#SGD_optimizer = optim.SGD(model_resnet.parameters(), lr=0.01, momentum=0.9) #SGD optimizer\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_ft = model_resnet.fc.in_features\n",
        "model_resnet.fc = nn.Sequential(nn.Dropout(p=0.25), nn.Linear(num_ft, 10))\n",
        "model_resnet = model_resnet.to('cuda')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "hIgpCsQUeX1_",
        "outputId": "0ae1b62c-80c7-4581-d112-3d58742a4e3f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Leaky ReLU\\nfrom torch.nn import LeakyReLU\\nclass LeakyBasicBlock(BasicBlock):\\n    def __init__(self, *args, **kwargs):\\n        super(LeakyBasicBlock, self).__init__(*args, **kwargs)\\n        self.relu = LeakyReLU(negative_slope=0.01, inplace=True)\\n\\n# ---- LeakyRELU ----- #\\nclass MFResNetLeaky(ResNet):\\n    def __init__(self):\\n        super(MFResNetLeaky, self).__init__(LeakyBasicBlock, [2, 2, 2, 2], num_classes=10) # Based on ResNet18\\n        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=1, padding=3, bias=False)\\n\\nmodel_resnet = MFResNetLeaky()\\n\\n#Create separate optimizers and criteria for Resnet\\nadam_optimizer = optim.Adam(model_resnet.parameters(), lr=0.001) #adam optimizer\\n#SGD_optimizer = optim.SGD(model_resnet.parameters(), lr=0.01, momentum=0.9) #SGD optimizer\\nloss_criterion = nn.CrossEntropyLoss()\\n\\nnum_ft = model_resnet.fc.in_features\\nmodel_resnet.fc = nn.Sequential(nn.Dropout(p=0.25), nn.Linear(num_ft, 10))\\nmodel_resnet = model_resnet.to('cuda')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG 16**"
      ],
      "metadata": {
        "id": "RUDBExRkRANs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG 16 CNN model"
      ],
      "metadata": {
        "id": "Q-15ce2HTT6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class ModifiedVGG16(VGG):\n",
        "    def __init__(self, num_classes=10):\n",
        "        features = vgg16(pretrained=False).features\n",
        "\n",
        "        # Remove the first MaxPool2d layer and the last three Conv2d layers\n",
        "        features = nn.Sequential(*list(features.children())[:-10])\n",
        "\n",
        "        super(ModifiedVGG16, self).__init__(features)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "\n",
        "vgg_model = ModifiedVGG16().cuda()\n",
        "\n",
        "# Create separate optimizers and criteria for ModifiedVGG16\n",
        "optimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
        "criterion_vgg = nn.CrossEntropyLoss()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "97qlCnrFRBW0",
        "outputId": "244ba4e7-261a-4e75-dd8a-4b2117d076f3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass ModifiedVGG16(VGG):\\n    def __init__(self, num_classes=10):\\n        features = vgg16(pretrained=False).features\\n\\n        # Remove the first MaxPool2d layer and the last three Conv2d layers\\n        features = nn.Sequential(*list(features.children())[:-10])\\n\\n        super(ModifiedVGG16, self).__init__(features)\\n        self.classifier = nn.Sequential(\\n            nn.Linear(512 * 7 * 7, 4096),\\n            nn.ReLU(True),\\n            nn.Dropout(),\\n            nn.Linear(4096, 4096),\\n            nn.ReLU(True),\\n            nn.Dropout(),\\n            nn.Linear(4096, num_classes),\\n        )\\n        self.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\\n\\n\\nvgg_model = ModifiedVGG16().cuda()\\n\\n# Create separate optimizers and criteria for ModifiedVGG16\\noptimizer_vgg = optim.Adam(vgg_model.parameters(), lr=0.001)\\ncriterion_vgg = nn.CrossEntropyLoss()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG 16 optimizer & loss criterion"
      ],
      "metadata": {
        "id": "YElD5fIPUC1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "optimizer_vgg_adam = optim.Adam(vgg_model.parameters(), lr=0.001)\n",
        "\n",
        "loss_criterion_vgg = nn.CrossEntropyLoss()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CmR0rp5tUJIU",
        "outputId": "97e53f45-398e-4192-d533-0b34c136cc70"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\noptimizer_vgg_adam = optim.Adam(vgg_model.parameters(), lr=0.001)\\n\\nloss_criterion_vgg = nn.CrossEntropyLoss()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of VGG 16 parallel to ResNet 18"
      ],
      "metadata": {
        "id": "yQzYIHEjUduM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "lst_unique = list(range(0, 10000, 1))\n",
        "batch_size = 1000\n",
        "lst_splits = [lst_unique[i:i + batch_size] for i in range(0, len(lst_unique), batch_size)]\n",
        "\n",
        "test_counts = [i*len(training_data.dataset) for i in range(3)]\n",
        "best_accuracy = 0\n",
        "average_accuracy = 0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "progress_bar_resnet18 = tqdm_notebook(iterable=range(num_epochs), position=0, leave=True, desc=\"ResNet 18 Progress\")\n",
        "progress_bar_vgg16 = tqdm_notebook(iterable=range(num_epochs), position=0, leave=True, desc=\"VGG 16 Progress\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "lst_training_losses_resnet18 = [] # Create an empty list to store training losses after each epoch for ResNet 18\n",
        "lst_training_losses_vgg16 = [] # Create an empty list to store training losses after each epoch for vgg16\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  model_resnet.train()\n",
        "  correct1 = 0\n",
        "  total1 = 0\n",
        "  correct2 = 0\n",
        "  total2 = 0\n",
        "  epoch_loss_1 = 0\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(training_data):\n",
        "\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    adam_optimizer.zero_grad()\n",
        "    output1 = model_resnet(data).cuda()\n",
        "    _, predicted = torch.max(output1, 1)\n",
        "    correct1 += (predicted == target).sum().item()\n",
        "    loss1 = loss_criterion(output1, target)             \n",
        "    total1 += target.size(0)\n",
        "    acc1 = (correct1 / total1) * 100.0\n",
        "    progress_bar_resnet18.set_description(f\"Loss Model 1: {loss1.item():.3f}, Main Data Accuracy Model 1: {acc1:.3f}\")\n",
        "    progress_bar_resnet18.update()\n",
        "    loss1.backward()\n",
        "    adam_optimizer.step()\n",
        "\n",
        "    lst_training_losses_resnet18.append(epoch_loss_1/len(training_data))    # Save training accuracy after each epoch\n",
        "\n",
        "\n",
        "  # Train VGG16\n",
        "  vgg_model.train()\n",
        "  correct_2 = 0\n",
        "  total_2 = 0\n",
        "  epoch_loss_2 = 0\n",
        "  for batch_idx, (data, target) in enumerate(training_data):\n",
        "      data, target = data.cuda(), target.cuda()\n",
        "      optimizer_vgg_adam.zero_grad()\n",
        "      output_2 = vgg_model(data).cuda()\n",
        "      _, predicted_2 = torch.max(output_2, 1)\n",
        "      correct_2 += (predicted_2 == target).sum().item()\n",
        "      loss_2 = loss_criterion(output_2, target)\n",
        "      total_2 += target.size(0)\n",
        "      acc_2 = (correct_2 / total_2) * 100.0\n",
        "      progress_bar_vgg16.set_description(f\"Loss Model 2: {loss_2.item():.3f}, Main Data Accuracy Model 2: {acc_2:.3f}\")\n",
        "      progress_bar_vgg16.update()\n",
        "      loss_2.backward()\n",
        "      optimizer_vgg_adam.step()\n",
        "\n",
        "      lst_training_losses_vgg16.append(epoch_loss_2/len(training_data))    # Save training accuracy after each epoch\n",
        "\n",
        "\n",
        "  torch.save(model_resnet.state_dict(), '/trained_model_1.pth')\n",
        "  torch.save(adam_optimizer.state_dict(), '/trained_optimizer_1.pth')\n",
        "  torch.save(vgg_model.state_dict(), '/trained_model_vgg16.pth')\n",
        "  torch.save(optimizer_vgg.state_dict(), '/trained_optimizer_vgg16.pth')\n",
        "\n",
        "# Close progress bars after the loop\n",
        "progress_bar_resnet18.close()\n",
        "progress_bar_vgg16.close()\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_Top_VdgUmqF",
        "outputId": "a341e3fb-0267-4d73-a116-c90fa96814ca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlst_unique = list(range(0, 10000, 1))\\nbatch_size = 1000\\nlst_splits = [lst_unique[i:i + batch_size] for i in range(0, len(lst_unique), batch_size)]\\n\\ntest_counts = [i*len(training_data.dataset) for i in range(3)]\\nbest_accuracy = 0\\naverage_accuracy = 0\\n\\nnum_epochs = 5\\n\\nprogress_bar_resnet18 = tqdm_notebook(iterable=range(num_epochs), position=0, leave=True, desc=\"ResNet 18 Progress\")\\nprogress_bar_vgg16 = tqdm_notebook(iterable=range(num_epochs), position=0, leave=True, desc=\"VGG 16 Progress\")\\n\\nstart_time = time.time()\\n\\nlst_training_losses_resnet18 = [] # Create an empty list to store training losses after each epoch for ResNet 18\\nlst_training_losses_vgg16 = [] # Create an empty list to store training losses after each epoch for vgg16\\n\\nfor epoch in range(num_epochs):\\n\\n  model_resnet.train()\\n  correct1 = 0\\n  total1 = 0\\n  correct2 = 0\\n  total2 = 0\\n  epoch_loss_1 = 0\\n\\n  for batch_idx, (data, target) in enumerate(training_data):\\n\\n    data, target = data.cuda(), target.cuda()\\n    adam_optimizer.zero_grad()\\n    output1 = model_resnet(data).cuda()\\n    _, predicted = torch.max(output1, 1)\\n    correct1 += (predicted == target).sum().item()\\n    loss1 = loss_criterion(output1, target)             \\n    total1 += target.size(0)\\n    acc1 = (correct1 / total1) * 100.0\\n    progress_bar_resnet18.set_description(f\"Loss Model 1: {loss1.item():.3f}, Main Data Accuracy Model 1: {acc1:.3f}\")\\n    progress_bar_resnet18.update()\\n    loss1.backward()\\n    adam_optimizer.step()\\n\\n    lst_training_losses_resnet18.append(epoch_loss_1/len(training_data))    # Save training accuracy after each epoch\\n\\n\\n  # Train VGG16\\n  vgg_model.train()\\n  correct_2 = 0\\n  total_2 = 0\\n  epoch_loss_2 = 0\\n  for batch_idx, (data, target) in enumerate(training_data):\\n      data, target = data.cuda(), target.cuda()\\n      optimizer_vgg_adam.zero_grad()\\n      output_2 = vgg_model(data).cuda()\\n      _, predicted_2 = torch.max(output_2, 1)\\n      correct_2 += (predicted_2 == target).sum().item()\\n      loss_2 = loss_criterion(output_2, target)\\n      total_2 += target.size(0)\\n      acc_2 = (correct_2 / total_2) * 100.0\\n      progress_bar_vgg16.set_description(f\"Loss Model 2: {loss_2.item():.3f}, Main Data Accuracy Model 2: {acc_2:.3f}\")\\n      progress_bar_vgg16.update()\\n      loss_2.backward()\\n      optimizer_vgg_adam.step()\\n\\n      lst_training_losses_vgg16.append(epoch_loss_2/len(training_data))    # Save training accuracy after each epoch\\n\\n\\n  torch.save(model_resnet.state_dict(), \\'/trained_model_1.pth\\')\\n  torch.save(adam_optimizer.state_dict(), \\'/trained_optimizer_1.pth\\')\\n  torch.save(vgg_model.state_dict(), \\'/trained_model_vgg16.pth\\')\\n  torch.save(optimizer_vgg.state_dict(), \\'/trained_optimizer_vgg16.pth\\')\\n\\n# Close progress bars after the loop\\nprogress_bar_resnet18.close()\\nprogress_bar_vgg16.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG 16 Test Prediction (without the store_csv function)"
      ],
      "metadata": {
        "id": "uL43EIDbVPIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "test_loader_final = test_data # This is the test data loader\n",
        "y_pred_vgg = []\n",
        "\n",
        "def pred_vgg16(testdata=test_data):\n",
        "    # evaluation mode\n",
        "    vgg_model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct_count = 0\n",
        "    y_pred_vgg = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for single_data in testdata:\n",
        "          # transfer data to cuda if available\n",
        "          data = data.to(device)\n",
        "\n",
        "          model_output = vgg_model(single_data)\n",
        "          prediction = model_output.data.max(1, keepdim=True)[1]\n",
        "          y_pred_vgg.append(prediction.tolist())\n",
        "\n",
        "    flattened_predictions = [item for sublist in y_pred_vgg for item in sublist] # Flatten the list, since the predictions are in a list of lists\n",
        "    final_predictions = [item for sublist in flattened_predictions for item in sublist] # Flatten the list, since the predictions are in a list of lists\n",
        "    return final_predictions\n",
        "\n",
        "startall = time.time()\n",
        "y_pred_vgg16 = pred_vgg16(testdata=test_data)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4d3BTyl4VS4h",
        "outputId": "793ffe66-ec57-4bef-cf18-f8d94eb11462"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntest_loader_final = test_data # This is the test data loader\\ny_pred_vgg = []\\n\\ndef pred_vgg16(testdata=test_data):\\n    # evaluation mode\\n    vgg_model.eval()\\n\\n    test_loss = 0\\n    correct_count = 0\\n    y_pred_vgg = []\\n    \\n    with torch.no_grad():\\n        for single_data in testdata:\\n          # transfer data to cuda if available\\n          data = data.to(device)\\n\\n          model_output = vgg_model(single_data)\\n          prediction = model_output.data.max(1, keepdim=True)[1]\\n          y_pred_vgg.append(prediction.tolist())\\n\\n    flattened_predictions = [item for sublist in y_pred_vgg for item in sublist] # Flatten the list, since the predictions are in a list of lists\\n    final_predictions = [item for sublist in flattened_predictions for item in sublist] # Flatten the list, since the predictions are in a list of lists\\n    return final_predictions\\n\\nstartall = time.time()\\ny_pred_vgg16 = pred_vgg16(testdata=test_data)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}